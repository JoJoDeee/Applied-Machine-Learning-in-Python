{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict whether a given blight ticket will be paid on time. \n",
    "\n",
    "**File descriptions** (Use only this data for training your model!)\n",
    "\n",
    "    readonly/train.csv - the training set (all tickets issued 2004-2011)\n",
    "    readonly/test.csv - the test set (all tickets issued 2012-2016)\n",
    "    readonly/addresses.csv & readonly/latlons.csv - mapping from ticket id to addresses, and from addresses to lat/lon coordinates. \n",
    "     Note: misspelled addresses may be incorrectly geolocated.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Data fields**\n",
    "\n",
    "train.csv & test.csv\n",
    "\n",
    "    ticket_id - unique identifier for tickets\n",
    "    agency_name - Agency that issued the ticket\n",
    "    inspector_name - Name of inspector that issued the ticket\n",
    "    violator_name - Name of the person/organization that the ticket was issued to\n",
    "    violation_street_number, violation_street_name, violation_zip_code - Address where the violation occurred\n",
    "    mailing_address_str_number, mailing_address_str_name, city, state, zip_code, non_us_str_code, country - Mailing address of the violator\n",
    "    ticket_issued_date - Date and time the ticket was issued\n",
    "    hearing_date - Date and time the violator's hearing was scheduled\n",
    "    violation_code, violation_description - Type of violation\n",
    "    disposition - Judgment and judgement type\n",
    "    fine_amount - Violation fine amount, excluding fees\n",
    "    admin_fee - $20 fee assigned to responsible judgments\n",
    "state_fee - $10 fee assigned to responsible judgments\n",
    "    late_fee - 10% fee assigned to responsible judgments\n",
    "    discount_amount - discount applied, if any\n",
    "    clean_up_cost - DPW clean-up or graffiti removal cost\n",
    "    judgment_amount - Sum of all fines and fees\n",
    "    grafitti_status - Flag for graffiti violations\n",
    "    \n",
    "train.csv only\n",
    "\n",
    "    payment_amount - Amount paid, if any\n",
    "    payment_date - Date payment was made, if it was received\n",
    "    payment_status - Current payment status as of Feb 1 2017\n",
    "    balance_due - Fines and fees still owed\n",
    "    collection_status - Flag for payments in collections\n",
    "    compliance [target variable for prediction] \n",
    "     Null = Not responsible\n",
    "     0 = Responsible, non-compliant\n",
    "     1 = Responsible, compliant\n",
    "    compliance_detail - More information on why each ticket was marked compliant or non-compliant\n",
    "\n",
    "\n",
    "___\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "Your predictions will be given as the probability that the corresponding blight ticket will be paid on time.\n",
    "\n",
    "The evaluation metric for this assignment is the Area Under the ROC Curve (AUC) and you have to make sure the score will be over 0.75.\n",
    "\n",
    "Example:\n",
    "\n",
    "    ticket_id\n",
    "       284932    0.531842\n",
    "       285362    0.401958\n",
    "       285361    0.105928\n",
    "       285338    0.018572\n",
    "                 ...\n",
    "       376499    0.208567\n",
    "       376500    0.818759\n",
    "       369851    0.018528\n",
    "       Name: compliance, dtype: float32\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2827: DtypeWarning: Columns (11,12,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ticket_id\n",
       "284932    0.110647\n",
       "285362    0.013576\n",
       "285361    0.068817\n",
       "285338    0.059938\n",
       "285346    0.073110\n",
       "285345    0.059938\n",
       "285347    0.060167\n",
       "285342    0.574059\n",
       "285530    0.013576\n",
       "284989    0.025204\n",
       "285344    0.053952\n",
       "285343    0.013576\n",
       "285340    0.013576\n",
       "285341    0.053952\n",
       "285349    0.073110\n",
       "285348    0.059938\n",
       "284991    0.025204\n",
       "285532    0.025204\n",
       "285406    0.025204\n",
       "285001    0.024838\n",
       "285006    0.021223\n",
       "285405    0.013576\n",
       "285337    0.025204\n",
       "285496    0.053952\n",
       "285497    0.059938\n",
       "285378    0.013576\n",
       "285589    0.025204\n",
       "285585    0.059938\n",
       "285501    0.068817\n",
       "285581    0.013576\n",
       "            ...   \n",
       "376367    0.030964\n",
       "376366    0.035058\n",
       "376362    0.189554\n",
       "376363    0.255693\n",
       "376365    0.030964\n",
       "376364    0.035058\n",
       "376228    0.035058\n",
       "376265    0.035058\n",
       "376286    0.323931\n",
       "376320    0.035058\n",
       "376314    0.035058\n",
       "376327    0.323931\n",
       "376385    0.323931\n",
       "376435    0.102723\n",
       "376370    0.934188\n",
       "376434    0.060167\n",
       "376459    0.076311\n",
       "376478    0.010920\n",
       "376473    0.035058\n",
       "376484    0.014676\n",
       "376482    0.016243\n",
       "376480    0.007002\n",
       "376479    0.007002\n",
       "376481    0.007002\n",
       "376483    0.019175\n",
       "376496    0.007641\n",
       "376497    0.007641\n",
       "376499    0.073110\n",
       "376500    0.073110\n",
       "369851    0.301345\n",
       "dtype: float32"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import logistic\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def blight_model():\n",
    "    train = pd.read_csv('train.csv',encoding = 'ISO-8859-1')\n",
    "    test = pd.read_csv('test.csv', encoding = \"ISO-8859-1\")     \n",
    "    train.set_index(train['ticket_id'],inplace = True)\n",
    "    test.set_index(test['ticket_id'],inplace = True)\n",
    "    adrresses = pd.read_csv('addresses.csv')\n",
    "    latlons = pd.read_csv('latlons.csv')\n",
    "    train.set_index(train['ticket_id'],inplace = True)\n",
    "    test.set_index(test['ticket_id'],inplace = True)\n",
    "    \n",
    "    # clean dataset\n",
    "    train.dropna(subset = ['compliance'],inplace = True)\n",
    "    train_uni_var = [\n",
    "        'balance_due',\n",
    "        'collection_status',\n",
    "        'compliance_detail',\n",
    "        'payment_amount',\n",
    "        'payment_date',\n",
    "        'payment_status'\n",
    "    ]\n",
    "     \n",
    "    train.drop(train_uni_var, inplace = True, axis = 1)\n",
    "    \n",
    "    train_text_var = ['agency_name', 'violation_street_number', 'mailing_address_str_number', 'state', 'violator_name', 'zip_code', 'country', 'city',\n",
    "                          'violation_street_name',\n",
    "                          'violation_zip_code', 'violation_description', 'mailing_address_str_name',\n",
    "                          'non_us_str_code',\n",
    "                          'ticket_issued_date', 'hearing_date', 'grafitti_status','discount_amount','clean_up_cost']\n",
    "    train.drop(train_text_var,inplace = True,axis = 1)\n",
    "    test.drop(train_text_var,inplace = True,axis = 1)\n",
    "    #encode important variables\n",
    "    \n",
    "    le = LabelEncoder().fit(train['disposition'].append(test['disposition'],ignore_index = True))\n",
    "    train['disposition']= le.transform(train['disposition'])\n",
    "    test['disposition'] = le.transform(test['disposition'])\n",
    "    \n",
    "    le = LabelEncoder().fit(train['violation_code'].append(test['violation_code'],ignore_index = True))\n",
    "    train['violation_code']= le.transform(train['violation_code'])\n",
    "    test['violation_code'] = le.transform(test['violation_code'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    features_name = ['judgment_amount','disposition','violation_code']\n",
    "    X_train = train[features_name]\n",
    "    y_train = train.compliance\n",
    "    \n",
    "    X_test = test[features_name]\n",
    "    \n",
    "    \n",
    "    #Using RandomForest and using grid search to find the best parameters (find 10,7 from the grid search)\n",
    "    clf = RandomForestClassifier(n_estimators = 10, max_depth = 7).fit(X_train,y_train)\n",
    "    params_grid ={'n_estimators':[3,5,8,10,15],'max_depth':[3,4,5,6,7]}\n",
    "    grid_clf = GridSearchCV(clf,param_grid = params_grid,scoring = 'roc_auc')\n",
    "    grid_clf.fit(X_train,y_train)\n",
    "    print('Best parameters are: ', grid_clf.best_params_)\n",
    "    print('The highest score (AUC): ', grid_clf.best_score_)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    \n",
    "    y_pred_prob = pd.Series(data = y_pred[:,1], index = test['ticket_id'],dtype = 'float32')\n",
    "    \n",
    "\n",
    "    # Using logistic regression\n",
    "    #clfLR = LogisticRegression().fit(X_train,y_train)\n",
    "    #y_pred_prob = clrLR.predict(X_test)[:,1]\n",
    "    \n",
    "    \n",
    "    return y_pred_prob\n",
    "\n",
    "blight_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "nNS8l",
   "launcher_item_id": "yWWk7",
   "part_id": "w8BSS"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
